import { systemPrompt } from "../../../lib/systemPrompt";
import { checkAndIncrementLimit } from "../../../lib/chatLimit";
import { getUserId } from "../../../lib/userId";
import { analyzeUserState } from "../../../lib/analyzeUserState";
import { buildSystemPrompt } from "../../../lib/buildSystemPrompt";
import { updatePseudoMemory } from "../../../lib/updatePseudoMemory";
import { getPseudoMemory } from "../../../lib/getPseudoMemory";

import { detectConversationMode } from "../../../lib/conversation/detectConversationMode";
import { modeInstructions } from "../../../lib/conversation/conversationModes";

import OpenAI from "openai";

export const runtime = "nodejs";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

const MAX_HISTORY = 20;

/**
 * üß≠ STYL KOTWICZNY ‚Äì ZEN
 * Partner do rozmowy, nie terapeuta, nie coach.
 */
const STYLE_ANCHOR = `
Jeste≈õ NaviMind.
Jeste≈õ partnerem do rozmowy, nie terapeutƒÖ.
Twoim celem jest pom√≥c jasno nazwaƒá problem lub sedno sytuacji.
Je≈õli widzisz sprzeczno≈õƒá, napiƒôcie lub niejasno≈õƒá ‚Äî nazwij jƒÖ wprost.
Nie moralizuj. Nie pocieszaj na si≈Çƒô.
My≈õl razem z u≈ºytkownikiem.
Je≈õli nie wiesz, co powiedzieƒá ‚Äî przyznaj to spokojnie.
`;

// üÜò Jedyny fallback ‚Äî pas bezpiecze≈Ñstwa, nic wiƒôcej
const FALLBACK_SENTENCE =
  "Chcƒô dobrze zrozumieƒá ‚Äî powiedz proszƒô, co jest teraz dla Ciebie najwa≈ºniejsze.";

export async function POST(req: Request) {
  try {
    const body = await req.json();
    const { messages, hiddenContext } = body;

    if (!Array.isArray(messages)) {
      throw new Error("messages is not an array");
    }

    // =========================
    // 1Ô∏è‚É£ USER + LIMIT
    // =========================
    const userId = getUserId();
    const limit = await checkAndIncrementLimit(userId);

    if (!limit.allowed) {
      return Response.json(
        {
          error: "LIMIT_REACHED",
          text:
            "Limit demo zosta≈Ç osiƒÖgniƒôty üîí\n\n" +
            "Masz 20 wiadomo≈õci na 24h.",
          limit: {
            used: limit.used,
            limit: limit.limit,
            resetAt: limit.resetAt,
          },
        },
        { status: 429 }
      );
    }

    // =========================
    // 2Ô∏è‚É£ HISTORIA (oczyszczona)
    // =========================
    let history = messages
      .filter(
        (m: any) =>
          m &&
          (m.role === "user" || m.role === "assistant") &&
          typeof m.content === "string"
      )
      .slice(-MAX_HISTORY);

    // nie zaczynamy rozmowy od asystenta
    if (history[0]?.role === "assistant") {
      history.shift();
    }

    // =========================
    // 3Ô∏è‚É£ ANALIZA STANU
    // =========================
    const analysis = await analyzeUserState(history);

    const lastUserMessage =
      history.filter((m: any) => m.role === "user").slice(-1)[0]?.content || "";

    const conversationMode = detectConversationMode(
      lastUserMessage,
      analysis
    );

    const modePrompt = modeInstructions[conversationMode];

    // =========================
    // 4Ô∏è‚É£ PSEUDO-PAMIƒòƒÜ
    // =========================
    const rawMemory = await getPseudoMemory(userId);
    const memory = rawMemory ?? { visits: 0 };

    const enrichedSystemPrompt = buildSystemPrompt(
      systemPrompt +
        "\n\nTRYB ROZMOWY:\n" +
        modePrompt,
      analysis,
      memory
    );

    await updatePseudoMemory(userId, analysis);

    // =========================
    // 5Ô∏è‚É£ PDF JAKO KONTEKST
    // =========================
    const documentContext = hiddenContext
      ? {
          role: "system",
          content:
            "U≈ºytkownik udostƒôpni≈Ç dokument PDF.\n" +
            "Traktuj go jako kontekst pomocniczy.\n" +
            "Nie streszczaj go.\n" +
            "Odpowiadaj wy≈ÇƒÖcznie na to, o co u≈ºytkownik pyta.\n\n" +
            hiddenContext.slice(0, 12000),
        }
      : null;

    // =========================
    // 6Ô∏è‚É£ AI RESPONSE
    // =========================
    const completion = await openai.chat.completions.create({
      model: "gpt-4.1-mini",
      temperature: 0.7,
      messages: [
        { role: "system", content: STYLE_ANCHOR },
        { role: "system", content: enrichedSystemPrompt },
        ...(documentContext ? [documentContext] : []),
        ...history,
      ] as any,
    });

    let text =
      completion.choices[0]?.message?.content?.trim() || "";

    // üÜò fallback tylko gdy model faktycznie nie ma tre≈õci
    if (!text || text.length < 10) {
      text = FALLBACK_SENTENCE;
    }

    // =========================
    // 7Ô∏è‚É£ RESPONSE DO UI
    // =========================
    return Response.json({
      text,
      limit: {
        used: limit.used,
        limit: limit.limit,
        resetAt: limit.resetAt,
      },
      uiHints: {
        returningUser: memory.visits >= 2,
        conversationMode,
      },
    });
  } catch (error) {
    console.error("CHAT API ERROR FULL:", error);

    return Response.json(
      { text: "Co≈õ siƒô wysypa≈Ço po stronie serwera." },
      { status: 500 }
    );
  }
}